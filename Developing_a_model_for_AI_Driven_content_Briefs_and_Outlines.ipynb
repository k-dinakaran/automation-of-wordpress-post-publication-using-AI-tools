{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu1Jhy+iy/3mbMOIns42cA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-dinakaran/automation-of-wordpress-post-publication-using-AI-tools/blob/main/Developing_a_model_for_AI_Driven_content_Briefs_and_Outlines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip setuptools wheel"
      ],
      "metadata": {
        "id": "EM0GfUKM5IjD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 498
        },
        "outputId": "91dc0491-4cbb-4327-d168-f3482a4cee87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Using cached pip-24.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (71.0.4)\n",
            "Collecting setuptools\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (0.44.0)\n",
            "Using cached pip-24.2-py3-none-any.whl (1.8 MB)\n",
            "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Installing collected packages: setuptools, pip\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 71.0.4\n",
            "    Uninstalling setuptools-71.0.4:\n",
            "      Successfully uninstalled setuptools-71.0.4\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pip-24.2 setuptools-75.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              },
              "id": "87447140abb549079b8f2aac6b23f8fb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YA7lY-Aluoj",
        "outputId": "15914315-d8bd-433d-ad3a-f701ef65877e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "import torch\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "model = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# Set pad_token_id to eos_token_id to fix the warning\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "# Step 1: Load and clean the dataset\n",
        "data = pd.read_csv('/content/content_brief.csv.csv')\n",
        "\n",
        "# Strip any leading/trailing whitespaces from strings in the dataset\n",
        "data_clean = data.apply(lambda x: x.str.strip() if x.dtype == \"object\" else x)\n",
        "\n",
        "# Step 2: Function to generate content brief and outline from the dataset\n",
        "def generate_content_brief_from_dataset(topic):\n",
        "    topic_lower = topic.lower()  # Convert topic to lowercase for matching\n",
        "\n",
        "    matching_row = data_clean[data_clean['Topic (Primary Input)'].str.lower().str.contains(topic_lower, na=False)]\n",
        "\n",
        "    if not matching_row.empty:\n",
        "        row = matching_row.iloc[0]  # Get the first matching row\n",
        "        content_brief = f\"\"\"\n",
        "        CONTENT BRIEF:\n",
        "              - Title: {row['Title Tag']}\n",
        "              - Meta Description: {row['Meta Description']}\n",
        "              - Target Audience: {row['Target Audience']}\n",
        "              - Keywords: {row['Keywords']}\n",
        "        OUTLINE:\n",
        "            - Introduction: {row['H1']}\n",
        "            - Main Points: {row['Questions']}\n",
        "        \"\"\"\n",
        "        return content_brief\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Step 3: Function to generate content brief using GPT-2 for new topics\n",
        "def generate_content_brief_with_gpt(topic):\n",
        "    prompt = (\n",
        "        f\"Write a well-structured content brief for a blog post on the topic '{topic}'. \"\n",
        "        \"The content brief should include the following sections:\\n\\n\"\n",
        "        \"1. **Title**: Give the post a compelling title.\\n\"\n",
        "        \"2. **Meta Description**: Write a meta description of 1-2 sentences.\\n\"\n",
        "        \"3. **Target Audience**: Specify the ideal audience for this post.\\n\"\n",
        "        \"4. **Keywords**: List 4-5 primary keywords.\\n\"\n",
        "        \"5. **Outline**:\\n\"\n",
        "        \"   - Introduction\\n\"\n",
        "        \"   - Main Points (3-4 key discussion points)\\n\\n\"\n",
        "        \"Content Brief:\\n\"\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
        "\n",
        "    outputs = model.generate(\n",
        "        inputs,\n",
        "        max_length=250,  # Limit output length\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=3,\n",
        "        pad_token_id=model.config.eos_token_id,\n",
        "        do_sample=True,\n",
        "        temperature=0.3,  # Lower temperature for more focused output\n",
        "        top_p=0.85\n",
        "    )\n",
        "\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    split_output = generated_text.split(\"Content Brief:\", 1)[-1]\n",
        "\n",
        "    # Return a structured fallback template if generation fails\n",
        "    if not split_output or \"Title\" not in split_output:\n",
        "        return f\"\"\"\n",
        "        CONTENT BRIEF:\n",
        "              - Title: How {topic} is Changing the Industry\n",
        "              - Meta Description: This post explores the key impacts of {topic} on modern businesses, technology, and society.\n",
        "              - Target Audience: Business leaders, technologists, and enthusiasts interested in {topic}.\n",
        "              - Keywords: {topic}, industry impact, technology trends\n",
        "        CONTENT OUTLINE:\n",
        "              - Introduction: Understanding {topic}\n",
        "              - Main Points:\n",
        "                1. Key areas where {topic} is making an impact.\n",
        "                2. The challenges and opportunities it presents.\n",
        "                3. How industries are adapting to {topic}.\n",
        "        \"\"\"\n",
        "    else:\n",
        "        return split_output.strip()\n",
        "\n",
        "# Step 4: User input for a new topic\n",
        "new_topic = input(\"Please enter the topic: \")\n",
        "\n",
        "# Step 5: Check if the topic exists in the dataset; if not, use GPT-2\n",
        "content_brief = generate_content_brief_from_dataset(new_topic)\n",
        "\n",
        "if content_brief:\n",
        "    print(f\"\\nContent Brief and Outline for '{new_topic}' (from dataset):\")\n",
        "    print(content_brief)\n",
        "else:\n",
        "    print(f\"\\nGenerating content brief for '{new_topic}' using GPT-2:\")\n",
        "    gpt_output = generate_content_brief_with_gpt(new_topic)\n",
        "    print(gpt_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-gugy1rZ8aH",
        "outputId": "af321259-47d5-4266-c353-603f83e1c746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter the topic: artificial intelligence in sport\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating content brief for 'artificial intelligence in sport' using GPT-2:\n",
            "\n",
            "        CONTENT BRIEF:\n",
            "              - Title: How artificial intelligence in sport is Changing the Industry\n",
            "              - Meta Description: This post explores the key impacts of artificial intelligence in sport on modern businesses, technology, and society.\n",
            "              - Target Audience: Business leaders, technologists, and enthusiasts interested in artificial intelligence in sport.\n",
            "              - Keywords: artificial intelligence in sport, industry impact, technology trends\n",
            "        CONTENT OUTLINE:\n",
            "              - Introduction: Understanding artificial intelligence in sport\n",
            "              - Main Points: \n",
            "                1. Key areas where artificial intelligence in sport is making an impact.\n",
            "                2. The challenges and opportunities it presents.\n",
            "                3. How industries are adapting to artificial intelligence in sport.\n",
            "        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vu5eRa6cbnMh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}