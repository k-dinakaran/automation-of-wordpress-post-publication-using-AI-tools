{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR2GCxCyBtgWsbQU5EHFft",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k-dinakaran/automation-of-wordpress-post-publication-using-AI-tools/blob/main/AI_driven_content_audit_tool_for_SEO_health.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests beautifulsoup4 nltk textstat\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWwI1sTP9f8x",
        "outputId": "4a007e5a-204c-4de7-efb9-67cbc4b652d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.10/dist-packages (0.7.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.8.30)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.10/dist-packages (from textstat) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (71.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "from collections import Counter\n",
        "import re\n",
        "import textstat  # Importing textstat for readability\n",
        "\n",
        "# Ensure you have the necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "\n",
        "def fetch_content(url):\n",
        "    \"\"\"Fetch content from a given URL.\"\"\"\n",
        "    headers = {\n",
        "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3\"\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        raise Exception(f\"Failed to fetch content from {url} with status code: {response.status_code}\")\n",
        "\n",
        "def extract_text_and_metadata(html_content):\n",
        "    \"\"\"Extract text and metadata from HTML content.\"\"\"\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "    text = soup.get_text(separator=' ', strip=True)\n",
        "\n",
        "    title = soup.title.string if soup.title else 'No title'\n",
        "    meta_description = soup.find('meta', attrs={'name': 'description'})\n",
        "    meta_description = meta_description['content'] if meta_description else 'No description'\n",
        "\n",
        "    return text, title, meta_description\n",
        "\n",
        "def analyze_keywords(text, keywords):\n",
        "    \"\"\"Analyze keyword density in the text.\"\"\"\n",
        "    words = nltk.word_tokenize(text.lower())\n",
        "    word_count = len(words)\n",
        "\n",
        "    keyword_count = Counter(words)\n",
        "    density_report = {keyword: (keyword_count[keyword.lower()] / word_count) * 100 for keyword in keywords}\n",
        "\n",
        "    return density_report, word_count\n",
        "\n",
        "def analyze_content_structure(soup):\n",
        "    \"\"\"Analyze the content structure for headings.\"\"\"\n",
        "    headings = {\n",
        "        'H1': len(soup.find_all('h1')),\n",
        "        'H2': len(soup.find_all('h2')),\n",
        "        'H3': len(soup.find_all('h3')),\n",
        "        'Bullets': len(soup.find_all(['ul', 'ol']))\n",
        "    }\n",
        "    return headings\n",
        "\n",
        "def calculate_readability(text):\n",
        "    \"\"\"Calculate the readability score using textstat.\"\"\"\n",
        "    return textstat.flesch_kincaid_grade(text)\n",
        "\n",
        "def generate_report(url, text, keyword_density, word_count, title, meta_description, headings, readability_score):\n",
        "    \"\"\"Generate SEO audit report.\"\"\"\n",
        "    print(f\"SEO Audit Report for: {url}\")\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Total Word Count: {word_count}\")\n",
        "    print(f\"Readability Score (Flesch-Kincaid Grade Level): {readability_score:.2f}\")\n",
        "    print(f\"\\nTitle: {title}\")\n",
        "    print(f\"Meta Description: {meta_description}\\n\")\n",
        "\n",
        "    print(\"Keyword Density Report:\")\n",
        "    for keyword, density in keyword_density.items():\n",
        "        print(f\" - {keyword}: {density:.2f}%\")\n",
        "\n",
        "    print(\"\\nContent Structure:\")\n",
        "    for heading, count in headings.items():\n",
        "        print(f\" - {heading}: {count}\")\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    # Recommendations\n",
        "    if readability_score > 12:\n",
        "        print(\"Recommendations:\")\n",
        "        print(\" - Consider simplifying your language to improve readability.\")\n",
        "\n",
        "    if len(keyword_density) == 0 or all(density == 0 for density in keyword_density.values()):\n",
        "        print(\" - Consider adding relevant keywords to the content.\")\n",
        "\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "def main():\n",
        "    # Input: URL and target keywords\n",
        "    url = input(\"Enter the URL of the content to audit: \")\n",
        "    keywords = input(\"Enter the keywords to analyze (comma-separated): \").split(',')\n",
        "\n",
        "    # Fetch and analyze content\n",
        "    try:\n",
        "        html_content = fetch_content(url)\n",
        "        text, title, meta_description = extract_text_and_metadata(html_content)\n",
        "        keyword_density, word_count = analyze_keywords(text, [k.strip() for k in keywords])\n",
        "        soup = BeautifulSoup(html_content, 'html.parser')\n",
        "        headings = analyze_content_structure(soup)\n",
        "        readability_score = calculate_readability(text)\n",
        "        generate_report(url, text, keyword_density, word_count, title, meta_description, headings, readability_score)\n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfs2y2Ge99na",
        "outputId": "74ea4c6d-e72b-42ba-8679-3b1ee1fb2b00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL of the content to audit: https://temstechsolutions.com/\n",
            "Enter the keywords to analyze (comma-separated): hiring,AI,jobs\n",
            "SEO Audit Report for: https://temstechsolutions.com/\n",
            "========================================\n",
            "Total Word Count: 576\n",
            "Readability Score (Flesch-Kincaid Grade Level): 32.90\n",
            "\n",
            "Title: Home - TEMS Tech Solutions\n",
            "Meta Description: No description\n",
            "\n",
            "Keyword Density Report:\n",
            " - hiring: 0.00%\n",
            " - AI: 0.35%\n",
            " - jobs: 0.35%\n",
            "\n",
            "Content Structure:\n",
            " - H1: 0\n",
            " - H2: 7\n",
            " - H3: 0\n",
            " - Bullets: 28\n",
            "========================================\n",
            "Recommendations:\n",
            " - Consider simplifying your language to improve readability.\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9CCU7gI2-B-L"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}